{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR is set to 0.01\n",
      "train: Loss: 178.2754\n",
      "valid: Loss: 272.2174\n",
      "train: Loss: 178.2750\n",
      "valid: Loss: 272.0581\n",
      "train: Loss: 178.2743\n",
      "valid: Loss: 271.9783\n",
      "train: Loss: 178.2735\n",
      "valid: Loss: 271.9276\n",
      "train: Loss: 178.2725\n",
      "valid: Loss: 271.8921\n",
      "LR is set to 0.004\n",
      "train: Loss: 178.2714\n",
      "valid: Loss: 271.8702\n",
      "train: Loss: 178.2709\n",
      "valid: Loss: 271.8526\n",
      "train: Loss: 178.2705\n",
      "valid: Loss: 271.8375\n",
      "train: Loss: 178.2700\n",
      "valid: Loss: 271.8249\n",
      "train: Loss: 178.2695\n",
      "valid: Loss: 271.8138\n",
      "LR is set to 0.0016000000000000003\n",
      "train: Loss: 178.2690\n",
      "valid: Loss: 271.8065\n",
      "train: Loss: 178.2688\n",
      "valid: Loss: 271.8005\n",
      "train: Loss: 178.2686\n",
      "valid: Loss: 271.7954\n",
      "train: Loss: 178.2684\n",
      "valid: Loss: 271.7914\n",
      "train: Loss: 178.2682\n",
      "valid: Loss: 271.7881\n",
      "LR is set to 0.0006400000000000002\n",
      "train: Loss: 178.2680\n",
      "valid: Loss: 271.7858\n",
      "train: Loss: 178.2679\n",
      "valid: Loss: 271.7841\n",
      "train: Loss: 178.2678\n",
      "valid: Loss: 271.7826\n",
      "train: Loss: 178.2677\n",
      "valid: Loss: 271.7816\n",
      "train: Loss: 178.2677\n",
      "valid: Loss: 271.7806\n",
      "LR is set to 0.00025600000000000004\n",
      "train: Loss: 178.2676\n",
      "valid: Loss: 271.7800\n",
      "train: Loss: 178.2676\n",
      "valid: Loss: 271.7795\n",
      "train: Loss: 178.2675\n",
      "valid: Loss: 271.7790\n",
      "train: Loss: 178.2675\n",
      "valid: Loss: 271.7785\n",
      "train: Loss: 178.2675\n",
      "valid: Loss: 271.7781\n",
      "LR is set to 0.00010240000000000002\n",
      "train: Loss: 178.2674\n",
      "valid: Loss: 271.7778\n",
      "train: Loss: 178.2674\n",
      "valid: Loss: 271.7776\n",
      "train: Loss: 178.2674\n",
      "valid: Loss: 271.7773\n",
      "train: Loss: 178.2674\n",
      "valid: Loss: 271.7771\n",
      "train: Loss: 178.2674\n",
      "valid: Loss: 271.7769\n",
      "LR is set to 4.0960000000000014e-05\n",
      "train: Loss: 178.2674\n",
      "valid: Loss: 271.7768\n",
      "train: Loss: 178.2674\n",
      "valid: Loss: 271.7766\n",
      "train: Loss: 178.2673\n",
      "valid: Loss: 271.7766\n",
      "train: Loss: 178.2673\n",
      "valid: Loss: 271.7765\n",
      "train: Loss: 178.2673\n",
      "valid: Loss: 271.7764\n",
      "LR is set to 1.6384000000000008e-05\n",
      "train: Loss: 178.2673\n",
      "valid: Loss: 271.7763\n",
      "train: Loss: 178.2673\n",
      "valid: Loss: 271.7763\n",
      "train: Loss: 178.2673\n",
      "valid: Loss: 271.7762\n",
      "train: Loss: 178.2673\n",
      "valid: Loss: 271.7762\n",
      "train: Loss: 178.2673\n",
      "valid: Loss: 271.7761\n",
      "LR is set to 6.553600000000004e-06\n",
      "train: Loss: 178.2673\n",
      "valid: Loss: 271.7761\n",
      "train: Loss: 178.2673\n",
      "valid: Loss: 271.7761\n",
      "train: Loss: 178.2673\n",
      "valid: Loss: 271.7761\n",
      "train: Loss: 178.2673\n",
      "valid: Loss: 271.7761\n",
      "train: Loss: 178.2673\n",
      "valid: Loss: 271.7761\n",
      "LR is set to 2.621440000000001e-06\n",
      "train: Loss: 178.2673\n",
      "valid: Loss: 271.7761\n",
      "train: Loss: 178.2673\n",
      "valid: Loss: 271.7761\n",
      "train: Loss: 178.2673\n",
      "valid: Loss: 271.7760\n",
      "train: Loss: 178.2673\n",
      "valid: Loss: 271.7760\n",
      "train: Loss: 178.2673\n",
      "valid: Loss: 271.7760\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class TNet(nn.Module):\n",
    "    def __init__(self,F,O):\n",
    "        super(TNet, self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            nn.Linear(F, int(F/2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(int(F/2),F),\n",
    "            nn.BatchNorm1d(F),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(F, O)\n",
    "            )\n",
    "#         self.sfmx = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "#         x = self.sfmx(x)\n",
    "        return x\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os, shutil, copy, math\n",
    "\n",
    "file = 'Training_Sample.csv'\n",
    "df = pd.read_csv(file)\n",
    "data_input = df.as_matrix()\n",
    "\n",
    "data = {}\n",
    "labl = {}\n",
    "data['train'] = torch.from_numpy(data_input[:-50,:-1]).float()#.unsqueeze(1)\n",
    "data['valid'] = torch.from_numpy(data_input[-50:,:-1]).float()#.unsqueeze(1)\n",
    "labl['train'] = torch.from_numpy(data_input[:-50,-1])\n",
    "labl['valid'] = torch.from_numpy(data_input[-50:,-1])\n",
    "\n",
    "def lr_scheduler(epoch, optimizer):\n",
    "    \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
    "    init_lr = 0.01\n",
    "    lr_decay_epoch = 5\n",
    "    lr = init_lr * (0.4**(epoch // lr_decay_epoch))\n",
    "    if epoch % lr_decay_epoch == 0: print('LR is set to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups: param_group['lr'] = lr\n",
    "    return\n",
    "\n",
    "PHASE = ['train','valid']\n",
    "model = TNet(16,1).cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.7)\n",
    "num_epochs = 50\n",
    "criterion = nn.L1Loss()\n",
    "for epoch in range(num_epochs):\n",
    "    for phase in PHASE:\n",
    "        if phase == 'train':\n",
    "            lr_scheduler(epoch,optimizer)\n",
    "            model.train(True)  # Set model to training mode\n",
    "        else:\n",
    "            model.train(False)  # Set model to evaluate mode\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(Variable(data[phase].cuda()))\n",
    "        preds = outputs.data.cpu()\n",
    "        loss = criterion(outputs, Variable(labl[phase].cuda().float()))\n",
    "        if phase == 'train': \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        running_loss = loss.data[0]\n",
    "        print('{:5}: Loss: {:.4f}'.format(phase, running_loss))    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
